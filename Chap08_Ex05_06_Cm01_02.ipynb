{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DRxXQE6qYhDB4eI6Ckl7GlZ5VdnZDVZF",
      "authorship_tag": "ABX9TyMevE5b2fQ7puLEBIdjO/9X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katsukiyamamoto/EU_M_Math/blob/main/Chap08_Ex05_06_Cm01_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ES-IFTUHMQPk",
        "outputId": "0117eee4-4c67-4fb3-b085-47eb99fd59d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'%.3f'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import numpy.random as random\n",
        "import scipy as sp\n",
        "from pandas import Series, DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import sklearn\n",
        "import requests, zipfile, io\n",
        "\n",
        "%precision 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8-5-1\n",
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-database/mushroom/agaricus-lepiota.data'\n",
        "res = requests.get(url).content\n",
        "\n",
        "mushroom = pd.read_csv(io.StringIO(res.decode('utf-8')), header=None)\n",
        "\n",
        "mushroom.columns = ['classes', 'cap_shape', 'cap_surface', 'cap_color', 'bruises', 'odor', 'gill_attachment', 'gill_spacing', 'gill_size', 'gill_color',\n",
        "                    'stalk_shape', 'stalk_root', 'stalk_surface_above_ring', 'stalk_surface_below_ring', 'stalk_color_above_ring',\n",
        "                    'stalk_color_below_ring', 'veil_type', 'veil_color', 'ring_number', 'ring_type', 'spore_print_color', 'population', 'habitat']\n",
        "\n",
        "mushroom.head()"
      ],
      "metadata": {
        "id": "5K8qWDyAVzIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('データの形式:{}'.format(mushroom.shape))\n",
        "print('欠損の数:{}'.format(mushroom.isnull().sum().sum()))"
      ],
      "metadata": {
        "id": "Io3vP43YVwGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8-5-2\n",
        "\n",
        "mushroom_dummy['flg'] = mushroom['classes'].map(lambda x: 1 if x == 'p' else 0)"
      ],
      "metadata": {
        "id": "yZIQFOXmVXdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8-5-3\n",
        "\n",
        "mushroom_dummy.groupyby(['cap_color_c','flg'])['flg'].count().unstack()\n",
        "\n",
        "mushroom_dummy.groupyby(['gill_color_b','flg'])['flg'].count().unstack()\n",
        "\n",
        "- (0.5 * np.log2(0.5) + 0.5 * np.log2(0.5))\n",
        "- (0.001 * np.log2(0.001) + 0.999 * np.log2(0.999))\n",
        "\n",
        "def calc_entropy(p):\n",
        "  return - (p * np.log2(p) + (1-p) * np.log2(1-p))\n",
        "\n",
        "p = np.arange(0.001, 0.999, 0.01)\n",
        "\n",
        "plt.plot(p, calc_entropy(p))\n",
        "plt.xlabel('prob')\n",
        "plt.ylabel('entropy')\n",
        "plt.grid(True)\n",
        "\n",
        "mushroom_dummy.groupyby('flg')['flg'].count()\n",
        "entropy_init = - (0.518 * np.log2(0.518) + 0.482 * np.log2(0.482))\n",
        "print('毒キノコデータのエントロピーの初期値:{:.3f}'.format(entropy_init))"
      ],
      "metadata": {
        "id": "WO686JQYV0tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8-5-4\n",
        "\n",
        "mushroom_dummy.groupyby(['cap_color_c','flg'])['flg'].count().unstack()\n",
        "\n",
        "p1 = 4176 / (4176 + 3904)\n",
        "p2 = 1 - p1\n",
        "\n",
        "entropy_c0 = -(p1 * np.log2(p1) + p2 * np.log2(p2))\n",
        "print('entropy_c0:{:.3f}'.format(entropy_c0))\n",
        "\n",
        "p1 = 32 / (32 + 12)\n",
        "p2 = 1 - p1\n",
        "\n",
        "entropy_c1 = -(p1 * np.log2(p1) + p2 * np.log2(p2))\n",
        "print('entropy_c0:{:.3f}'.format(entropy_c1))\n",
        "\n",
        "entropy_after = (4176+3904)/8124*entropy_c0 + (32+12)/8124*entropy_c1\n",
        "print('データ分割後の平均エントロピー:{:.3f}'.format(entropy_after))\n",
        "\n",
        "print('変数cap_colorの分割によって得られる情報利得:{:.3f}'.format(entropy_init - entropy_after))\n",
        "\n",
        "\n",
        "mushroom_dummy.groupyby(['gill_color_b','flg'])['flg'].count().unstack()\n",
        "\n",
        "p1 = 4208 / (4208 + 2188)\n",
        "p2 = 1 - p1\n",
        "\n",
        "entropy_b0 = -(p1 * np.log2(p1) + p2 * np.log2(p2))\n",
        "\n",
        "p1 = 0 / (0 + 1728)\n",
        "p2 = 1 - p1\n",
        "\n",
        "entropy_b1 = -(p1 * np.log2(p1) + p2 * np.log2(p2))\n",
        "\n",
        "entropy_after = (4208+2188)/8124*entropy_b0 + (0+1728)/8124*entropy_b1\n",
        "print('変数gill_colorの分割によって得られる情報利得:{:.3f}'.format(entropy_init - entropy_after))"
      ],
      "metadata": {
        "id": "KN37B48fXg05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8-5-5\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = mushroom_dummy.drop('flg', axis=1)\n",
        "y = mushroom_dummy['flg']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
        "\n",
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=5 random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('正解率(train):{:.3f}'.format(model.score(X_train, y_train)))\n",
        "print('正解率(test):{:.3f}'.format(model.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "Vkt2MZ6laNzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RandomForestClassifier\n",
        "\n",
        "from sklearn.tree import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = mushroom_dummy.drop('flg', axis=1)\n",
        "y = mushroom_dummy['flg']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
        "\n",
        "model = RandomForestClassifier(criterion='entropy', max_depth=5 random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('正解率(train):{:.3f}'.format(model.score(X_train, y_train)))\n",
        "print('正解率(test):{:.3f}'.format(model.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "9wt7d1ykauwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8-7-1\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify = cancer.target, random_state=0)\n",
        "\n",
        "model = LinearSVC()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "print('正解率(train):{:.3f}'.format(model.score(X_train,y_train)))\n",
        "print('正解率(test):{:.3f}'.format(model.score(X_test,y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgL-wxFRYDG6",
        "outputId": "0e3870f5-87f2-4ed2-efca-f3892d516385"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正解率(train):0.930\n",
            "正解率(test):0.923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(cancer.data, cancer.target, stratify = cancer.target, random_state=0)\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "\n",
        "\n",
        "model = LinearSVC()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "print('正解率(train):{:.3f}'.format(model.score(X_train,y_train)))\n",
        "print('正解率(test):{:.3f}'.format(model.score(X_test,y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bguUKpLJb7ha",
        "outputId": "33bc82f5-8c78-48a3-9074-5a2579ac86e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正解率(train):0.934\n",
            "正解率(test):0.930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#練習問題8-8\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test= train_test_split(cancer.data, cancer.target, stratify = cancer.target, random_state=50)\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "\n",
        "\n",
        "model = SVC(kernel='rbf', random_state=0, C=2)\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "print('正解率(train):{:.3f}'.format(model.score(X_train,y_train)))\n",
        "print('正解率(test):{:.3f}'.format(model.score(X_test,y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yxps7G6cs7w",
        "outputId": "4e67d889-9558-4211-98d2-ec5069656fe3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正解率(train):0.920\n",
            "正解率(test):0.937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 総合問題8-1\n",
        "\n",
        "### 回帰（Regression）\n",
        "**意味**: 数値データの予測を目的とした手法。目標変数（ラベル）が連続値の場合に使用される。\n",
        "\n",
        "**使用される場面**: 家賃の予測、気温の予測、株価の予測など。\n",
        "\n",
        "### 分類（Classification）\n",
        "**意味**: カテゴリデータの予測を目的とした手法。目標変数（ラベル）がカテゴリ値（クラスラベル）の場合に使用される。\n",
        "\n",
        "**使用される場面**: スパムメールの識別、画像認識、病気の診断など。\n",
        "\n",
        "###教師あり学習（Supervised Learning）\n",
        "**意味**: ラベル付きデータを使用してモデルを訓練する機械学習手法。予測対象となる正解データが存在する。\n",
        "\n",
        "**使用される場面**: 既知のデータに基づいて新しいデータの結果を予測する場合に使用。\n",
        "\n",
        "###重回帰分析（Multiple Regression）\n",
        "**意味**: 複数の独立変数を使用して従属変数を予測する回帰手法。単純な線形回帰の拡張。\n",
        "\n",
        "**使用される場面**: 経済学における複数の要因が売上に与える影響の分析など。\n",
        "\n",
        "###ロジスティック回帰（Logistic Regression）\n",
        "**意味**: 二項または多項のカテゴリ変数を予測するための回帰分析手法。確率のログを利用。\n",
        "\n",
        "**使用される場面**: バイナリ分類問題（例えば、顧客が製品を購入するかどうかの予測）に頻繁に使用。\n",
        "\n",
        "###正則化（Regularization）\n",
        "**意味**: モデルの過学習を防ぐためにペナルティを追加する手法。モデルの複雑さを制御する。\n",
        "\n",
        "**使用される場面**: 過学習を防ぎ、モデルの汎化性能を向上させるために使用。\n",
        "\n",
        "###リッジ回帰（Ridge Regression）\n",
        "**意味**: L2正則化を使用する回帰手法。回帰係数の二乗和をペナルティとして追加。\n",
        "\n",
        "**使用される場面**: 高次元データや共線性があるデータセットに対して使用。\n",
        "\n",
        "###ラッソ回帰（Lasso Regression）\n",
        "**意味**: L1正則化を使用する回帰手法。回帰係数の絶対値の和をペナルティとして追加。\n",
        "\n",
        "**使用される場面**: 特徴選択が重要な場合（多くの特徴の中から重要なものを選択）に使用。\n",
        "\n",
        "###決定木（Decision Tree）\n",
        "**意味**: データを分割し、分岐を利用して予測を行うツリーベースの手法。\n",
        "\n",
        "**使用される場面**: 直感的で解釈しやすいモデルが求められる場合や、非線形関係があるデータに使用。\n",
        "\n",
        "###エントロピー（Entropy）\n",
        "**意味**: 不確実性や情報の混乱度を測定する指標。決定木の分割基準の一つ。\n",
        "\n",
        "**使用される場面**: 決定木の構築において、最適な分割を見つけるために使用。\n",
        "\n",
        "###情報利得（Information Gain）\n",
        "**意味**: 分割によって得られる情報の増加量を示す指標。エントロピーの減少量として計算される。\n",
        "\n",
        "**使用される場面**: 決定木の各ノードの分割基準として使用。\n",
        "\n",
        "###k-NN法（k-Nearest Neighbors）\n",
        "**意味**: 新しいデータポイントをk個の近傍データポイントの多数決や平均で分類・回帰する手法。\n",
        "\n",
        "**使用される場面**: シンプルで非パラメトリックな手法が適している場合や、小規模データセットに使用。\n",
        "\n",
        "###サポートベクターマシン（SVM）\n",
        "**意味**: データポイントを分類するために、最大マージンを持つハイパープレーンを見つける手法。\n",
        "\n",
        "**使用される場面**: 高次元データや複雑な非線形分類問題に使用。\n",
        "\n",
        "###ノーフリーランチ定理（No Free Lunch Theorem）\n",
        "**意味**: すべての機械学習アルゴリズムがすべての問題に対して等しく有効であるわけではないという定理。\n",
        "\n",
        "**使用される場面**: 特定のアルゴリズムがある特定の問題に対して特に適している理由を理解するために使用。"
      ],
      "metadata": {
        "id": "ou8mFqVVe5n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#総合問題8-2\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test= train_test_split(cancer.data, cancer.target, stratify = cancer.target, random_state=0)\n",
        "\n",
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('正解率(train):{:.3f}'.format(model.score(X_train,y_train)))\n",
        "print('正解率(test):{:.3f}'.format(model.score(X_test,y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh9ss8G0eRub",
        "outputId": "d6dce8e5-5b13-478f-9d45-d8fe27fa862d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正解率(train):0.977\n",
            "正解率(test):0.923\n"
          ]
        }
      ]
    }
  ]
}